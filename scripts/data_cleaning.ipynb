{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "504a8927",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a0a1a796",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_file_path = \"E:\\\\Super_Store_Sales\\\\csv_files\\\\Superstore_Sales_Dataset.csv\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9ecad452",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:1: SyntaxWarning: invalid escape sequence '\\S'\n",
      "<>:1: SyntaxWarning: invalid escape sequence '\\S'\n",
      "C:\\Users\\okkj\\AppData\\Local\\Temp\\ipykernel_8744\\1368018279.py:1: SyntaxWarning: invalid escape sequence '\\S'\n",
      "  output_folder = \"E:\\Super_Store_Sales\\csv_files\"\n"
     ]
    }
   ],
   "source": [
    "output_folder = \"E:\\Super_Store_Sales\\csv_files\"\n",
    "cleaned_file_name = \"Superstore_Sales_Dataset_Cleaned.csv\"\n",
    "cleaned_file_path = os.path.join(output_folder, cleaned_file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "92cef7c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(output_folder):\n",
    "    os.makedirs(output_folder)\n",
    "    print(f\"The output folder has been created: {output_folder}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d45f0850",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Data\n",
    "data = pd.read_csv(raw_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e091587b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropping 'Row ID' column...\n"
     ]
    }
   ],
   "source": [
    "# Drop the 'Row ID' column if it exists\n",
    "if 'Row ID' in data.columns:\n",
    "    print(\"Dropping 'Row ID' column...\")\n",
    "    data = data.drop(columns=['Row ID'])\n",
    "else:\n",
    "    print(\"'Row ID' column not found, skipping drop.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "77fb4a65",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\okkj\\AppData\\Local\\Temp\\ipykernel_8744\\3687546683.py:5: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  data['Postal Code'].fillna('N/A', inplace=True)\n",
      "C:\\Users\\okkj\\AppData\\Local\\Temp\\ipykernel_8744\\3687546683.py:5: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value 'N/A' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  data['Postal Code'].fillna('N/A', inplace=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converting 'Postal Code' to string and cleaning...\n"
     ]
    }
   ],
   "source": [
    "# Convert 'Postal Code' to string type (handling potential floats/ints)\n",
    "if 'Postal Code' in data.columns:\n",
    "    print(\"Converting 'Postal Code' to string and cleaning...\")\n",
    "    # Fill in the missing values ​​first\n",
    "    data['Postal Code'].fillna('N/A', inplace=True)\n",
    "    # Convert all to text\n",
    "    data['Postal Code'] = data['Postal Code'].astype(str)\n",
    "    # Remove '.0' at the end of the text if present (resulting from decimal conversion)\n",
    "    data['Postal Code'] = data['Postal Code'].str.replace(r'\\\\.0$', '', regex=True)\n",
    "    # Ensure there are no values ​​like 'nan' or '<NA>'.\n",
    "    data['Postal Code'] = data['Postal Code'].replace({'<NA>': 'N/A', 'nan': 'N/A'}, regex=False)\n",
    "else:\n",
    "    print(\"'Postal Code' column not found, skipping conversion.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "dee58d95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converting date columns to datetime objects (format MM/DD/YYYY)...\n"
     ]
    }
   ],
   "source": [
    "# Convert date columns to datetime format\n",
    "print(\"Converting date columns to datetime objects (format MM/DD/YYYY)...\")\n",
    "if 'Order Date' in data.columns:\n",
    "    data['Order Date'] = pd.to_datetime(data['Order Date'], format='%m/%d/%Y', errors='coerce')\n",
    "else:\n",
    "    print(\"Warning: 'Order Date' column not found.\")\n",
    "\n",
    "if 'Ship Date' in data.columns:\n",
    "   data['Ship Date'] = pd.to_datetime(data['Ship Date'], format='%m/%d/%Y', errors='coerce')\n",
    "else:\n",
    "    print(\"Warning: 'Ship Date' column not found.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ba54f74d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Found 5841 rows with invalid 'Order Date' format.\n",
      "Warning: Found 5985 rows with invalid 'Ship Date' format.\n"
     ]
    }
   ],
   "source": [
    "# Check for any rows where date conversion failed (resulted in NaT)\n",
    "nat_order_dates = data['Order Date'].isnull().sum() if 'Order Date' in data.columns else 0\n",
    "nat_ship_dates = data['Ship Date'].isnull().sum() if 'Ship Date' in data.columns else 0\n",
    "if nat_order_dates > 0:\n",
    "    print(f\"Warning: Found {nat_order_dates} rows with invalid 'Order Date' format.\")\n",
    "if nat_ship_dates > 0:\n",
    "    print(f\"Warning: Found {nat_ship_dates} rows with invalid 'Ship Date' format.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "5ca0a177",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Save the clean data to a new file E:\\Super_Store_Sales\\csv_files\\Superstore_Sales_Dataset_Cleaned.csv\n",
      "The new file was saved successfully.\n",
      "\n",
      "The cleaning process is complete.\n"
     ]
    }
   ],
   "source": [
    "print(f\"\\nSave the clean data to a new file {cleaned_file_path}\")\n",
    "try:\n",
    "    # Using encoding=\"utf-8-sig\" ensures best compatibility with Excel (especially for Arabic)\n",
    "    data.to_csv(cleaned_file_path, index=False, encoding='utf-8-sig')\n",
    "    print(\"The new file was saved successfully.\")\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred while saving the new file: {e}\")\n",
    "\n",
    "print(\"\\nThe cleaning process is complete.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
